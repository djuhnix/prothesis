[["index.html", "Automatisation des processus de sécurité Chapitre 1 Résumé", " Automatisation des processus de sécurité Germain Jr. OLEA-OYOUGOU 15 septembre 2024 Chapitre 1 Résumé La question de l’automatisation des processus de sécurité naît du constat de l’incapacité des équipes de sécurité à suivre l’évolution des méthodologies de gestion de projets qui nous emmènent à livrer de plus en plus rapidement nos produits et se retrouvent avec une charge de travail qui aurait pu être amoindri en amont. Cette thèse professionnelle traitera des différents processus de sécurité dans les phases de prévention de détection et de réponse et des possibilités d’automatisation de ces derniers. En partant de l’origine des besoins de la sécurité de l’information elle donnera des détails sur pourquoi et comment automatiser un processus. Sur la base des travaux de docteurs en sécurité informatique et les rapports de diverses conférences parlant d’automatisation, elle montrera les recommandations de l’industrie en ce qui concerne la mise en place de processus automatisés au sein d’une organisation. Elle argumente sur l’avantage du Shift Left et des pratiques DevSecOps en donnant des pistes de solutions sur l’adoption d’une approche automatisée de la sécurité dans le contexte de Shadow et en avertissant sur les risques de trop se fier à un système totalement automatisé. "],["glossaire.html", "Chapitre 2 Glossaire", " Chapitre 2 Glossaire Shift-Left : Intégrer les tests et la sécurité dès les premières phases du développement pour détecter les problèmes plus tôt. DevOps : Méthode combinant développement et opérations pour livrer des logiciels plus rapidement et de manière fiable. DevSecOps : Extension de DevOps intégrant la sécurité dès le début du cycle de développement. NTA : Analyse du trafic réseau pour détecter des comportements suspects ou des menaces. IDS/IPS : Systèmes qui détectent (IDS) et préviennent (IPS) les intrusions ou activités malveillantes. EDR/XDR : Solutions de sécurité pour détecter et répondre aux menaces sur les terminaux (EDR) ou à travers plusieurs couches (XDR). Delivery first : Approche visant à livrer rapidement des fonctionnalités ou produits fonctionnels. CI/CD : Automatisation des tests (CI) et du déploiement (CD) dans le développement logiciel. Linting : Analyse du code pour détecter des erreurs ou des violations des conventions de codage. Packaging : Compilation du code en un package ou une unité exécutable pour déploiement. Build : Compilation du code en une application exécutable, incluant tests et gestion des dépendances. "],["déclaration-sur-lhonneur.html", "Chapitre 3 Déclaration sur l’honneur", " Chapitre 3 Déclaration sur l’honneur Je déclare sur l’honneur que cette thèse professionnelle est le fruit d’un travail personnel et que je n’ai ni contrefait, ni falsifié, ni copié tout ou partie de l’œuvre d’autrui afin de la faire passer pour mienne. Toutes les sources d’information utilisées (supports papiers, audiovisuels et numériques) et les citations d’auteur ont été mentionnées conformément aux usages en vigueur. Je suis conscient que le fait de ne pas citer une source ou de ne pas la citer clairement et complètement est constitutif de plagiat, que le plagiat est considéré comme une faute grave au sein de l’Université de Technologie de Troyes (UTT) et qu’il peut être sévèrement sanctionné. Je confirme que les propos écrits n’engagent que moi et en aucune façon ni l’UTT ni toute autre partie prenante. "],["introduction.html", "Chapitre 4 Introduction", " Chapitre 4 Introduction Mes deux ans d'alternance au sein de la société Shadow m'ont montré à quel point elle déploie des efforts pour optimiser son processus de déploiement. Shadow possède deux produits : Shadow PC, un ordinateur à hautes performances dans le Cloud accessible depuis n’importe quel périphérique et Shadow Drive, le stockage en ligne souverain. La gestion de ces deux produits nécessite le développement de plusieurs outils internes, avec cela un nombre de processus de maintenance assez élevés. Pour garder un niveau de qualité élevé et une rapidité dans ces processus, Shadow a misé sur l'automatisation du déploiement de nombreux de ses services avec la mise en place de pratiques DevOps assez avancées. Au sein de l'équipe sécurité nous avons senti le besoin de s'adapter à cette évolution en procédant à un Shift Left, c’est-à-dire insérer les tests de sécurité au plus tôt au sein du cycle de développement pour trouver et corriger les vulnérabilités le plus tôt possible. En opposé au Shift Right qui consiste à exécuter des tests, surveiller le comportement de l’utilisateur et les paramètres de sécurité quand le produit est déjà opérationnel. La plupart des décisions de sécurité sont prises lors des processus de développement et de mise en condition opérationnelle par ces équipes et les équipes de sécurité ne prennent que très rarement des décisions qui impliquent directement le produit mais plutôt quand il s’agit d’évaluer ou atténuer un risque. Il est difficile de se prémunir de catastrophes commerciales et métier en appliquant des mesures avant la définition des stratégies de sécurité. Pourtant ce mode de fonctionnement est encore courant et ralentit la vélocité des équipes de développement. Pour éviter de découvrir des vulnérabilités trop tard et de ne réagir qu’en cas d’incident, il est intéressant de se demander comment la mise en place des pratiques de sécurité automatisées au sein des processus de développement peut améliorer la résistance des systèmes d'information aux menaces qui pèsent sur une organisation et augmenter la performance des équipes de sécurité. En tant qu’apprenti chez Shadow j’ai eu le rôle de mener une analyse comparative et de mettre en place ces pratiques afin d’évaluer l’apport en productivité de l’amélioration de nos processus. Notre objectif à présent est de confronter les visions communes et acceptées par l’industrie sur ce sujet en apportant des pistes d’amélioration et en ajoutant de la valeur sur les défauts apparents. De ce fait pour développer la réponse à cette problématique nous allons étudier l’état de l’art en matière d’automatisation des processus de sécurité et les bénéfices que cela peut apporter tout en analysant les méthodologies de mise en place des pratiques et les outils à intégrer. En parallèle nous discuterons de l’implémentation de ces mesures au sein de Shadow, nous créerons un environnement propice à la pratique des compétences nécessaires à la mise en place de ces méthodologies. Enfin nous ne manquerons pas de lister les limites de ces pratiques et d’aborder les sujets allant au-delà de cette problématique. Toutefois nous ne saurons commencer sans relater le contexte de la sécurité de l’information et les raisons derrière l’automatisation des processus qui font ce domaine. "],["etat-de-lart-de-lautomatisation-des-processus-de-sécurité.html", "Chapitre 5 Etat de l'art de l'automatisation des processus de sécurité 5.1 Contexte sur l’automatisation des processus de sécurité 5.2 Introduction à l’automatisation 5.3 Prévention et DevSecOps 5.4 Détection de nouvelles menaces 5.5 Réponse automatisée à un incident", " Chapitre 5 Etat de l'art de l'automatisation des processus de sécurité 5.1 Contexte sur l’automatisation des processus de sécurité 5.1.1 La sécurité informatique Pour contextualiser notre sujet, revenons aux origines et définissons la sécurité informatique. L'objectif de l'informatique est la gestion automatique de l'information et la sécurité informatique implique la sécurité de l'information c'est-à-dire le maintien de la confidentialité, intégrité et la disponibilité de ces informations. Ces trois points sont les piliers de la sécurité informatique. Le principe de confidentialité stipule que l’information ne doit être accessible qu’aux personnes autorisées, l’intégrité est la garantie que l’information ne soit pas corrompue, dégradée ou modifiée et la disponibilité est l’assurance que l’information soit accessible aux personnes autorisées au moment où elles en ont besoin. La sécurité de l’information n’est pas figée, elle est plutôt le résultat d’un processus d’amélioration continue, c’est-à-dire qui évolue à travers différentes phases et se perfectionne tout le long. Il s’agit d’un voyage et pas une destination. Bien qu’il y ait de nombreuses étapes dans ce voyage nous pouvons néanmoins les regrouper dans trois grandes phases : la prévention, la détection et la réponse (incluant la remédiation) (LaPiedra, 2002). 5.1.1.1 La prévention La prévention consiste à se préparer en amont pour se prévenir de futurs incidents. Notre objectif est de protéger l’information de toutes dégradations, altération ou accès non autorisé. Pour cela la phase de prévention implique : La définition de politiques de sécurité : savoir ce qui doit être protégé en décrivant des règles claires, concises et précises. La mise en place d’un programme de sensibilisation à la sécurité de l’information pour éduquer toute l’équipe aux bonnes pratiques de sécurité et aux risques que court l’organisation L’implémentation des contrôles d’accès : restreindre l’accès et n’autoriser que les permissions nécessaires à la fonction de l’utilisateur. Identifier correctement les principes d’identification, authentification et autorisation dans chaque processus d’accès. 5.1.1.2 La détection Se protéger est idéal mais détecter est indispensable. Tout système d’information est vulnérable et sujet à compromission. Keith Alexander, général de la United States Army et directeur de la National Security Agency (NSA) affirme durant la U.S. Chamber of Commerce Cybersecurity Summit en 2012 : Either you know you’ve been hacked, or you’ve been hacked and you don’t know you’ve been hacked que nous pouvons traduire par : soit vous savez que vous avez été attaqué soit vous avez été attaqué mais vous ne le savez pas encore. En effet, peu importe le niveau de protection d’un système d’information, ce n’est qu’une question de temps avant qu’il ne soit compromis par un acteur ayant assez de compétences et de motivation. D’où l’importance d’un système de détection de d’intrusion et de compromission (IDS). Le facteur le plus crucial dans une stratégie de détection est le temps moyen entre l'infection et la détection ajoutée à la précision de la notification en cas de compromission : une détection plus rapide et une notification plus précise amélioreront l'efficacité du processus d'investigation et de réponse en cas d'incident. 5.1.1.3 La réponse La réponse consiste à réagir face à l’annonce d’un nouvel incident ou d’une compromission. La phase de réponse donne toute sa valeur à une détection de qualité. Néanmoins, une bonne réponse ne s’improvise pas. Le stress que nous ressentons lors d’une attaque ne permet pas de prendre de bonnes décisions. Il existe des méthodologies de réponse à incident permettant d’adapter son plan de réponse à son métier et à l’incident subit. Celui du NIST (National Institute of Standards and Technology) et du SANS se distingue dans le schéma suivant. Nous commençons toujours par l’étape de préparation qui se déroule en général avant l’arrivée de l’incident. La détection arrive ensuite, nous devons identifier et analyser le type d’attaque que nous subissons, son origine et idéalement l’auteur de l’attaque. Après cela le confinement vise à réduire l’impact de l’incident, l’éradication à supprimer la menace du système d’information et la reprise à remettre le système en condition opérationnelle. Enfin la dernière étape consiste toujours à faire une revue de la gestion de l’incident et sert à améliorer le processus de réponse en lui-même. Une bonne réponse à incident nécessite un processus rapide qui aboutit à une remédiation dans un court laps de temps. Au-delà d’une succession optimale des étapes susmentionnées, nous devons noter que la vitesse de ce processus passe par une remontée efficace des informations nécessaire à l’équipe lors de la détection même l’incident. Le SANS précise que The process of detecting malicious or accidental misuse of resources is much more than sounding an alarm. Also, responding to an incident is much more than just showing up. An organization to be successful must know what to detect and once alerted know how to effectively coordinate resources for a response. Pour poursuivre, une bonne détection est de même liée à une préparation et une prévention correcte. Là se trouvent les principaux maux de la sécurité informatique : Ils prennent du temps Ils nécessitent beaucoup de bande passante (de charge de travail, de personnes qualifiées) Ils sont coûteux en ressources et en argent Cela décourage certaines organisations à entamer le voyage dont nous parlons. Comment donc faire en sorte de corriger ces barrières tout en facilitant l’adoption des pratiques de sécurité ? Chez Shadow nous avons un programme de sécurité établi par Florent notre responsable sécurité. Après avoir fait l’état des lieux et défini les politiques nécessaires et les actions à prendre pour commencer notre voyage, ce dernier inclut une phase d’automatisation des processus de sécurité au sein du cycle de développement mais également dans les tâches quotidiennes de l’équipe en charge de la sécurité. 5.1.2 Les processus de sécurité automatisées Dans un monde idéal, nous n'aurions pas à répondre à des incidents ou, du moins, nous n'aurions qu'à traiter des incidents dignes de notre attention. L'une des solutions pour parvenir à ce monde idéal serait d'automatiser les processus répétitifs. Le docteur Brian Carrier définit l’automatisation en disant : Automation is when the computer does the next step without human intervention1 De ce fait l’automatisation des processus de sécurité permettrait : Une réduction des tâches manuelles de bas niveau : pour libérer du temps à l'équipe sécurité et lui permettre de se concentrer sur les tâches nécessitant plus d'attention. Une réponse rapide aux incidents : pour réduire le MTTD (Mean Time To Detect — temps moyen de détection) et le MTTR (Mean Time To Repair — temps moyen de réparation) comme expliqué plus haut. Une standardisation des processus : car une plateforme automatisée suivra toujours les règles que nous lui donnons, éliminant ainsi les erreurs d'opérations manuelles et apportant de la cohérence. Un gain de productivité général pour l'équipe. Cependant, l'automatisation n'est pas l'unique option. Les autres solutions consistent à optimiser la réalisation des processus en améliorant ceux qui en dépendent. Par exemple, nous pouvons limiter le temps de réponse à un incident en maximisant les indicateurs que nous remontent nos systèmes de détection d'intrusion (IDS). Nous pouvons également élever le niveau de notre détection en connaissant profondément notre système d'information. En effet, une connaissance parfaite de son SI et de ses services permet de configurer finement ses outils de détection et de remonter les événements. En continuant avec cette idée, on éviterait le nombre d'événements remontés en prévenant le nombre de vulnérabilités dans nos applications, réduisant ainsi notre surface d'attaque et, par transitivité, le risque auquel nous sommes soumis. D'où l'importance de la phase de prévention. Une grosse partie de la prévention est de faire en sorte que les applications et logiciels que nous sortons soient sécurisés, nous arrivons donc à la sécurisation du cycle de développement. 5.1.3 Le cycle de développement sécurisé Tenant ses origines des années 1960, la sécurité dans le SDLC — Software Development Lifecycle — et toutes les méthodologies s’en inspirant, quand elle est incluse, se positionne comme un jalon la gestion de projet entre certaines étapes du SDLC. Une porte à franchir pour passer à l’étape suivante. Nous avons généralement dans les équipes soucieuses de la sécurité de leur produit La revue des spécifications et de la conception du produit : après l’étape d’identification La revue de l’architecture : après l’étape de conception La revue du code : après l’étape de création ou développement Les tests de sécurité : après l’étape des tests. Laura Bell précise dans son livre Agile Application Security que l’idée derrière ces jalons soit de réaliser des livrables en lot car It is predicated on the old rule that the earlier a defect is caught, the cheaper it is to fix; therefore we need to do a security review as early as possible to catch security defects before they get too far. (Bell, Brunton-Spall, Smith, &amp; Bird, 2017, p. 79) Sauf que notre problématique persiste. Effectivement, les processus et pratiques de sécurité telles que nous les connaissons ont été conçues pour une gestion de projet en cascade où les besoins sont décidés bien avant et pas pour des petites équipes évoluant rapidement et de manière itérative. En optant pour une approche Agile, la solution ne consisterait pas à résoudre tous les problèmes de sécurité avant la mise en production, mais plutôt à se concentrer sur la réduction du coût de correction, en rendant les futurs changements sans risque et plus facilement réalisables. We want to reach a fine balance between finding and fixing (or better, preventing) security problems up front where it makes sense to do so, and making sure that we can fix them quickly and cheaply later if something gets by. (Bell, Brunton-Spall, Smith, &amp; Bird, 2017, p. 79) La première approche pour répondre à cela est l’apparition du principe Shift Left2, c’est-à-dire inclure des tests de sécurité à chaque étape du SDLC. Nous obtenons ce dont les experts appellent le SSDLC — Secure Development Lifecycle — ou SDL pour faire court. (Voir annexe 1) Une approche plus récente avec la montée en charge des pratiques DevOps et l’augmentation exponentielle des menaces de sécurité, permet d’aller encore plus loin et favorise les entreprises à se préparer et à actualiser fréquemment l’ensemble de ses processus de sécurité de la prévention à la réponse : le modèle DevSecOps avec un accent particulier sur l’automatisation. Dans le parcours de la sécurité chez Shadow, j’ai eu l’honneur d’avoir la responsabilité de mettre en place certaines de ces pratiques. Cependant, maintenant que nous savons pourquoi l’automatisation peut être un acteur positif à l’évolution des processus de sécurité, découvrons ce qui se fait de mieux avant d’aborder concrètement les actions menées au sein de notre organisation. 5.2 Introduction à l’automatisation Avant de parler d’automatisation et de pratiques DevSecOps, nous devons savoir Quoi automatiser et Quand automatiser. Mentionné plus tôt, le Dr. Brian Carrier défini trois niveaux d’automatisation pour compléter sa définition Manuelle : c’est-à-dire aucune présence de quelconque automatisation. Partielle : une automatisation présente mais ayant besoin de quelques interactions humaines. Totale : définissant un processus totalement automatisé. Quand nous souhaitons automatiser, nous devons choisir le niveau d'automatisation selon que : le bénéfice qu’apportera la réalisation automatique de la prochaine étape du processus soit assez élevé le coût humain, logiciel et matériel de la mise en place du processus automatique soit abordable dans notre contexte la probabilité qu’une erreur survienne et son impact extérieur à son contexte soit acceptable Sachant que plus une automatisation devient complexe, plus le besoin en ressources matérielles et en maintenance se fait grand, nous devons évaluer ces paramètres non seulement au début de la phase de réflexion de la mise en place de notre processus automatisé mais aussi à chaque fois que nous souhaitons faire évoluer notre niveau d’automatisation. En ce qui concerne le cycle de développement notre objectif en faisant du Shift Left est d’accompagner le développeur et de lui faire un retour continu sur son code. Voyant ce que nous apporte le DevSecOps sur ce chemin. 5.3 Prévention et DevSecOps Plus qu’une recette miracle ou un terme new age, le DevSecOps est une approche et une philosophie qui comme les principes Agiles favorise la collaboration entre les équipes dans l’objectif de détecter au plus tôt les problèmes de sécurité et les vulnérabilités diverses. L’OWASP dit dans le projet OWASP DevSecOps Guideline The Ideal goal is “detect security issues (by design or application vulnerability) as fast as possible.”3 On peut voir le DevSecOps comme une aide et un ensemble de bonnes pratiques dans la mise en place d’un cycle de développement sécurisé. 5.3.1 Culture DevSecOps Le terme DevSecOps suppose l’engagement des équipes développement, sécurité et opérationnelle. Sauf que cette approche va au-delà de la définition même de ces équipes et implique tous les métiers agissant sur le cycle de développement pour les rendre responsables de la sécurité : du chef de projet aux développeurs en passant par les designers, les architectes, etc. De plus Shannon Lietz — fondateur de la DevSecOps Foundation dit The purpose and intent of DevSecOps is to build on the mindset that “everyone is responsible for security” with the goal of safely distributing security decisions at speed and scale to those who hold the highest level of context without sacrificing the safety required.”4 Pour cela, nous devons sensibiliser nos équipes à la culture DevSecOps et mettre en place des outils pour parvenir à une stratégie de Shift Left performante. L'étape préalable consiste à comprendre l'importance d'un esprit de collaboration, ce qui constitue une base solide pour le partage des bonnes pratiques de sécurité au sein des équipes. Cela facilite également le travail des équipes de sécurité dans la compréhension de leurs politiques par les collaborateurs. D’où la nécessité d’un programme de sensibilisation à la sécurité informatique. Notamment la compréhension des vulnérabilités venant des standards comme le OWASP Top 10 ou le CWE top 25. 5.3.2 Comprendre son besoin en sécurité Avant de se lancer dans un programme de mise en place de pratiques DevSecOps une organisation doit prendre en compte son niveau de maturité pour pouvoir formaliser son besoin de sécurité et pouvoir le traduire en tant que processus automatisé. Un article de Shannon Lietz présente une pyramide pour hiérarchiser les besoins en sécurité d’un logiciel à la manière de la pyramide de Maslow.5 Hiérarchiser ses besoins permet de mieux répartir nos efforts dans la mise en place de politique de sécurité. Nous l’avons dit, la sécurité informatique n’est pas figée, ainsi nos politiques doivent être faites selon la culture, les objectifs et les politiques organisationnelles de l’entreprise. De la même manière notre approche vers l’automatisation de nos processus de sécurité ne doit pas être figée à un unique standard. Nous devons prendre en compte les contraintes de chaque outil avant de faire notre choix, s’assurer que toute l’équipe adopte un schéma de pensé aligné avec l’idée de ne pas faire de choix qui sembleraient couvrir tous les besoins existant mais plutôt s’orienter vers des solutions qui répondent à un besoin particulier. Par exemple choisir un outil pour un langage de programmation spécifique quand cela est pertinent plutôt qu’un autre promettant de réaliser un traitement sur tous types de langage mais sans réelle efficacité. Il existe des outils qui nous aident dans l’évaluation de notre niveau de maturité et nous permettent de savoir comment hiérarchiser nos besoins. L’OWASP Software Assurance Maturity Model (SAMM) par exemple est un cadre qui a pour objectif d’accompagner les organisations à formuler et à mettre en place une stratégie de sécurité logicielle parfaitement adaptée aux risques spécifiques auxquels l’organisation est confrontée. L’OWASP DevSecOps Maturity Model (DMM) est l’équivalent du SAMM pour les pratiques DevSecOps, ce cadre évalue le niveau de mise en place de pratiques DevSecOps au sein de l’organisation, nous aidant à hiérarchiser nos besoins dans notre approche de sécurisation de notre cycle de développement. 5.3.3 Conception sécurisé et industrialisation des tests Une fois qu’une culture de collaboration est établie et que nous savons où orienter nos efforts, nous devons accompagner l’équipe de développement dans la réalisation de sa tâche tout en l’aidant à livrer une application sécurisée. Laura Bell dit dans Agile Application Security Security teams that try to reduce risk by minimizing change, rather than supporting development teams to realize their ideas in a secure way, are doomed to be increasingly irrelevant in an Agile world, and will therefore be bypassed. \\[...\\] Security professionals have to learn to accept change, to work faster and more iteratively, and be able to think about security risks, and how to manage risks, in incremental terms. And most important, security needs to become an enabler, instead of a blocker. (Bell, Brunton-Spall, Smith, &amp; Bird, 2017, p. 76) Dans cette direction, qui s’aligne avec le fait de prévenir la découverte de vulnérabilités au plus tôt, notre rôle revient à se retrouver dans le quotidien de l’équipe de développement et au sein de ses outils. Cela se traduit notamment dans la mise en place de revue de code sécurisé d’un programme de Security Champion, qui est collaborateur de l’équipe ayant un rôle de développeur ou d’opérationnelle en charge de partager une culture de sécurité et de s’assurer du respect des politiques de sécurité lors des développements. de tests de sécurité directement dans les cycles d’intégration et de déploiement continu (CI/CD) Le modèle OWASP d’un cycle de livraison continu adapté aux tests de sécurité se présente grossièrement comme suite Ces étapes consistent concrètement à : Parcourir les dépôts git à la recherche d'identifiants ou de valeurs secrètes exposés publiquement. Analyser le code source de l'application ou du logiciel à déployer pour découvrir de potentielles vulnérabilités (Static Application Security Testing — SAST). Analyser l'ensemble des composants et librairies dont dépend le code source pour se prémunir des risques de sécurité liés à la compromission de ces derniers (Software Component Analysis — SCA). Réaliser des tests de sécurité sur l'application pendant qu'elle s'exécute, similaire à une activité de tests de pénétration en boîte noire. L'objectif est de retrouver des failles et des vulnérabilités donnant des accès non autorisés aux données (Dynamic Application Security Testing — DAST). Analyser le code destiné à la création dynamique de l'infrastructure pour éviter les erreurs liées à une mauvaise configuration ou une implémentation inadéquate (Infrastructure as Code Scanning — IaC). Analyser l'infrastructure en elle-même pour vérifier l'exposition et la surface d'attaque de l'environnement. Tester l'application des politiques définies et la conformité aux différents standards liés à notre industrie (Compliance Check). Ces dernières se réalisent bien évidemment de manière automatique pour apporter un retour continu aux développeurs dans la correction des vulnérabilités remontées. Mais l'automatisation ne s'arrête pas là. Nous verrons dans la suite que nous pouvons encore faire évoluer l'automatisation de certains de nos processus, mais également quels outils nous permettront d'implémenter ces actions, notamment dans le contexte de Shadow. Le guide OWASP DevSecOps Guideline6 détaille chacune de ces étapes et apporte des clés et des outils en source ouverte pour nous aider dans notre démarche. 5.3.4 Surveiller continuellement De nos jours, les attaquants ne cessent de renouveler leurs techniques d'attaque en profitant du principe de confiance établi entre les environnements et les composants de notre système d'information et ceux de nos organisations partenaires. Certaines méthodes non conventionnelles prolifèrent, notamment en prenant avantage des services en SaaS et en Cloud, car l'attaquant peut facilement s'y introduire et se servir de la base de confiance que nous avons en ces services pour pénétrer au sein de notre environnement. C'est le principe d'une attaque en Supply Chain. Ce genre d'attaque est difficile à reconnaître et donne aux attaquants un bon moyen de contourner les outils de détection mis en place. De plus, nos environnements ne sont pas encore prêts pour les détecter. De la même manière que les méthodes d'attaque évoluent, les techniques de détection doivent évoluer. En effet, de la détection d'intrusion réseau et machine que nous connaissons, nous devons tendre vers une détection proche de la logique de l'application et du logiciel en cours de développement. Shannon Lietz dit : The natural evolution of security is from network to host to software. C'est-à-dire étudier et comprendre comment notre produit fonctionne et est utilisé pour faire remonter les comportements déviants. Cela implique un développement qui prend en compte une récolte de données importante et pertinente pour une investigation. Surveiller continuellement, c'est instrumentaliser l'analyse de ces données pour avoir une vision claire du comportement de notre produit en permanence. Cela nécessite un investissement de temps et d'efforts pour comprendre quels sont ces comportements déviants à l'utilisation normale de notre application dans un premier temps, puis comment implémenter les logiques de détection de ces comportements au sein de nos outils. Par exemple, quand nous avons une application d'administration conçue pour être utilisée entre 8 h et 17 h et qu'un utilisateur se connecte à 00 h, nous devons journaliser cet événement de manière particulière pour permettre aux outils de sécurité de lancer une alerte et déclencher une intervention. Pour aller plus loin dans le processus d'automatisation, dans certains cas, l'application peut être conçue et développée pour s'auto-remédier face à ce type de comportement pré-identifié. En somme, ces pratiques issues de l'approche DevSecOps nous permettent de Shift Left, c'est-à-dire détecter les causes d'un manque de sécurité au plus tôt dans le cycle de développement. Comme dit le manifeste DevSecOps : We will not wait for our organizations to fall victim to mistakes and attackers. We will not settle for finding what is already known; instead, we will look for anomalies yet to be detected. En réalisant tout cela dans notre phase de prévention de la menace, nous sommes déjà à l'abri de 99% des attaques courantes. Toutefois, comme nous l'avons déjà abordé, sans détection efficace, nous restons des cibles faciles pour des techniques d'attaque nouvelle génération. Voyons donc comment, en mettant en avant l'automatisation de nos processus, nous pouvons tendre vers l'optimisation de notre système de détection. 5.4 Détection de nouvelles menaces La détection est une phase du cycle de sécurité d'une organisation dont l'objectif est d'identifier les menaces présentes au sein du système d'information ou du réseau de cette dernière. Ces menaces peuvent être présentes sous la forme de logiciels malveillants, d'une première prise de contact comme un phishing ou d'un premier accès au réseau, comme une analyse de ports ouverts. Ce processus devrait également être automatisé pour qu'il soit pleinement utile à l'équipe. En effet, beaucoup d'équipes réalisent encore aujourd'hui des investigations manuelles pour faire de la détection de bas niveau, ce qui est malheureusement sujet à des erreurs humaines et à un risque de non-détection de certaines menaces. Automatiser la détection de menaces implique d'avoir un bon niveau de surveillance des événements sur les terminaux de notre système informatique. Cela va de pair avec une bonne stratégie de notification et réduction du temps à la détection de la menace. James LaPiedra dit dans un document de la certification GIAC du SANS : defense in layers strategy should be deployed so when each layer fails, it fails safely to a known state and sounds an alarm (LaPiedra, 2002) Cela devient encore plus vrai face à la montée croissante de nouvelles sortes d'attaques devenant de plus en plus complexes à identifier. D'un autre côté, les anciennes sont facilement identifiables grâce à leur signature particulière et leur schéma déjà bien connu. Dans ce contexte, nous avons tout à y gagner à faire confiance à des outils qui se chargent de ces tâches à notre place pour que nous puissions nous concentrer sur la levée de suspicions sur une menace ou l'identification de menaces plus critiques. Beaucoup de solutions existent aujourd'hui pour nous accompagner dans cette phase, chacune à différents niveaux du système d'information. 5.4.1 Détection au sein du réseau L'analyse du trafic réseau ou Network Traffic Analysis (NTA) est une pratique cruciale dans la sécurité d’un système informatique, visant à surveiller et à analyser le trafic réseau pour détecter les anomalies, les menaces et les comportements malveillants. En combinant diverses technologies, elle permet une détection et une aide à la réponse proactives aux incidents de sécurité. Nous avons notamment 5.4.1.1 Les IDS Les systèmes de détection d’intrusions (IDS), essentiels pour l'analyse du trafic réseau. Surveille le réseau et identifie les activités suspectes ou malveillantes. Comme Snort, un IDS open source très populaire qui analyse le trafic en temps réel et détecte diverses attaques et intrusions. Chez Shadow nous avons pu mettre en place CrowdSec une solution de sécurité qui analyse les logs applicatifs pour détecter et prévenir les intrusions. Ne se limitant pas qu’à cette tâche, je la présenterai plus loin dans le contexte de la mise en place de détection de la menace au sein de Shadow. 5.4.1.2 La suite Elastic Stack (ELK) Elastic Stack, également connu sous le nom de ELK (Elasticsearch, Logstash, Kibana), est une suite d'outils open source pour la gestion et l'analyse des données : Collecte et ingestion de données (Logstash) : Agrège et traite les données de diverses sources. Recherche et analyse (Elasticsearch) : Fournit des capacités de recherche et d'analyse performantes. Visualisation des données (Kibana) : Permet la création de tableaux de bord interactifs pour visualiser et explorer les données de sécurité. Le choix et l'intégration de ces technologies NTA permettent de renforcer la visibilité sur le réseau, d'améliorer la détection des menaces et de réagir rapidement aux incidents de sécurité, contribuant ainsi à une posture de sécurité globale plus robuste et réactive. 5.4.2 Détection au sein des terminaux du système informatique Pour détecter les menaces sur nos terminaux de manière automatique nous avons les technologies de Détection et Réponse sur les Endpoints (Endpoint Detection and Response — EDR) et Détection et Réponse Étendues (EXtended Detection and Response — XDR). Elles sont cruciales pour la surveillance et la sécurisation des points d'accès réseau, des serveurs et des postes de travails de nos collaborateurs. Elles permettent de détecter, d'analyser et de répondre aux menaces de manière proactive, assurant une protection renforcée des infrastructures informatiques. L'EDR se concentre sur la détection et la réponse aux menaces directement sur les endpoints (postes de travail, serveurs, appareils mobiles), utilisant des techniques avancées pour identifier les comportements suspects et les activités malveillantes mais également fournir des fonctionnalités adéquates pour enquêter sur les incidents de sécurité et prendre des mesures correctives. OpenEDR par exemple est une solution open source qui offre une visibilité complète sur les activités des endpoints, permettant de détecter et de répondre aux menaces en temps réel. OpenEDR est conçu pour être flexible et extensible, ce qui le rend adapté à une variété d'environnements de sécurité. Non seulement il détecte les menaces, mais il permet également aux administrateurs de comprendre l'ampleur des incidents et de mettre en place des réponses efficaces pour limiter les impacts. L'XDR va au-delà de l'EDR en intégrant des données provenant de plusieurs sources de sécurité pour offrir une visibilité et une protection plus globales. Il combine des données de sécurité provenant des endpoints, des réseaux, des serveurs et des applications pour une vue holistique des menaces. Il permet une analyse centralisée des menaces et une réponse coordonnée à travers l'ensemble de l'infrastructure. Nous pouvons citer Wazuh comme plateforme open source qui offre des capacités de détection et de réponse étendues. Wazuh intègre des fonctionnalités de surveillance des fichiers, de gestion des configurations, de détection des anomalies et de réponse aux incidents, couvrant ainsi un large spectre de sources de données de sécurité. L'utilisation de solutions EDR et XDR comme OpenEDR et Wazuh permet aux organisations de renforcer leur posture de sécurité en offrant une visibilité accrue et une capacité de réponse améliorée aux menaces. Ces technologies sont essentielles pour détecter et neutraliser les cyberattaques avant qu'elles ne causent des dommages significatifs. Chez Shadow nous avons fait le choix d’intégrer Wazuh à la gamme de nos outils de détection pour couvrir tous nos serveurs de données et machines virtualisées. Un sujet que nous développerons plus loin dans ce document. 5.4.3 Gestion des événements détecter Bien que ces solutions de détection soient suffisantes ; la gestion des informations et des événements de sécurité ou Security Information and Event Management (SIEM) est une approche et une solution essentielle à avoir en matière de détection, elle combine la gestion des informations de sécurité (SIM) et la gestion des événements de sécurité (SEM). Elle permet une analyse en temps réel des alertes de sécurité, contribuant à la détection, la prévention et la réponse aux menaces et incidents de sécurité, tout en assurant la conformité réglementaire des organisations. Elle implique de récolter un grand nombre d’informations des différentes solutions intégrées et de les centraliser pour pouvoir les traiter proprement et faciliter le travail des analystes. Voici un aperçu de quelques solutions SIEM majeures et leurs caractéristiques distinctives. 5.4.3.1 IBM QRadar IBM QRadar est une plateforme SIEM de premier plan qui se distingue par : Détection avancée des menaces : Utilisation de l'apprentissage automatique et de l'analyse comportementale. Réponse intégrée aux incidents : Capacités de réponse rapides et efficaces. Scalabilité : Adaptée aux grandes entreprises. Gestion de la conformité : Conformité avec des normes telles que le RGPD, HIPAA et PCI-DSS. 5.4.3.2 SPLUNK Splunk est réputé pour sa gestion des grandes quantités de données générées par les machines. Ses caractéristiques incluent : Surveillance en temps réel : Alertes instantanées sur les menaces. Ingestion de données polyvalente : Adaptabilité à divers environnements. Recherche et visualisation performantes : Capacités de recherche approfondies et visualisations intuitives. Tableaux de bord personnalisables : Suivi des indicateurs de performance spécifiques. 5.4.3.3 Datadog Cloud SIEM Datadog Cloud SIEM, une solution native du cloud, offre : Architecture native du cloud : Déploiement facile et évolutivité. Surveillance unifiée : Intégration avec les autres services de Datadog. Détection automatisée des menaces : Algorithmes d'apprentissage automatique pour la détection proactive. Gestion des incidents : Outils efficaces pour une réponse rapide. Avoir une approche de gestion des événements de sécurité avec une solution SIEM doit prendre en compte la taille de l'organisation, des exigences spécifiques en matière de sécurité, des impératifs de conformité et de l'infrastructure informatique existante. Cela permet de renforcer la posture de sécurité de l'organisation face aux menaces cybernétiques croissantes. James LaPierda dit sur la détection This is more of an art than a science. \\[...\\] (It) is much more than an alarm. Although it is an alarm, it’s an alarm with brains. Car une détection est d’autant plus efficace qu’elle donne les éléments nécessaires à une bonne investigation et accompagne ainsi la réponse à incident. Il est vrai qu’un pompier ne pas intervenir s’il ne connaît pas l’adresse de son incident. Toutefois notre détection peut être inefficace sans plan de réponse, nous ne devons pas attendre une alerte pour se préparer à y répondre. Il est donc temps d’étudier comme y parvenir tout en évaluant les possibilités d’automatisation de ces processus. 5.5 Réponse automatisée à un incident En phase de réponse notre objectif est de comprendre ce qui s’est passé sur notre système d’information grâce aux précieuses données obtenues lors de la phase de détection dans le but de trouver l’attaquant, réparer les dégâts que nous aurions subis et minimiser l’impact de son activité sur notre métier. Nous l’avons vu plus haut, une réponse à incident de manière traditionnelle se déroule en différentes étapes selon la méthodologie du SANS ou du NIST. D’un point de vue technique, utile dans une philosophie d’automatisation, le Docteur Brian Carrier regroupe ces étapes en deux grands processus : l’investigation et l’atténuation ou mitigation. 5.5.1 L’investigation Pendant l’investigation nous devons collecter et analyser les données de nos terminaux impactés par l’attaque ou susceptible d’être compromis. Nous procédons en général en définissant premièrement des questions auxquelles nous n’avons pas encore des réponses en collectant les données nécessaires pour répondre à ces questions en analysant ces données pour y retirer de l’information intelligente en répondant enfin à nos questions Concrètement nos questions seront orientées selon l’avancée de notre réponse. En début d’investigation nous allons d’abord chercher à trier les données reçues pour se focaliser sur les pistes qui nous semblent le plus pertinentes (c’est l’étape de triaging). Nous allons nous demander quels sont les terminaux compromis, à quel niveau sont-ils impactés, etc. ? Si notre phase de détection est optimale nous aurions déjà la réponse à certaines de ces questions. Ensuite nous allons approfondir notre questionnement en nous demandant, qui est l’acteur présent au sein de notre système, quand a-t-il pénétré notre réseau, quels sont ses objectifs ? À ce moment nous faisons de l’analyse forensique pour corréler nos données collecter avec les actions de l’attaquant pour en extraire des informations factuelles. Cette étape nous amène à approfondir davantage le questionnement afin de trouver des preuves tangibles, comme la recherche d'un fichier spécifique sur une machine distante dans un état déterminé. 5.5.2 L’atténuation Durant l’étape d’atténuation notre souhait est de minimiser l’impact de l’attaque en cours ou subis. Cela peut être de bloquer les connexions réseaux sur les machines compromises. L’atténuation est cruciale pour empêcher l’avancée de l’attaque en plus de nous faire gagner du temps dans l’élimination de la menace. Elle devrait en principe se faire en parallèle de l’investigation, dès la détection de la menace. Cependant certaines équipes priorisent d’autres tâches de réponse par manque de ressources humaines. Ce procédé dépend de l’attaque subie, ainsi nous n’automatiserons pas l’atténuation d’une infection par un fichier malveillant ou d’une attaque par dénis de service. Notre processus doit donc prendre en compte les éléments fournis lors de la phase de détection pour orienter les actions à mener. Nous pouvons également ajouter sur cette optique d’automatisation le procédé de remédiation qui consiste à remettre en condition opérationnelle nos services. De même un processus de remédiation dépend du type d’attaque subie mais en plus elle dépend également de notre architecture et des composants compromis. À chacune de ces étapes nous devons évaluer le niveau d’automatisation voulu comme aborder plus haut pour pouvoir ajuster nos efforts à nos besoins. Voyant à quoi cela peut ressembler pour la plupart des organisations. 5.5.3 Automatisation contextuelle Toujours en se basant sur l’approche du Dr Brian Carrier, dans la majorité des organisations nous allons vouloir premièrement automatiser en totalité les étapes qui ne nécessitent pas une prise de décision humaine. En effet, nous pensons que ces personnes ont davantage tendance à classer leurs alertes, préfèrent sous-traiter les enquêtes complexes et ne disposent pas de suffisamment de ressources pour investir dans une plateforme d'apprentissage qui les aiderait à comprendre ce qui est habituel et comment coordonner les différentes phases de la réponse, y compris les environnements honeypot et autres. 5.5.3.1 La collecte de données L’Agence Nationale de la Sécurité de Systèmes d’Information nous propose DFIR ORC (Outil de recherche de compromission), qui nous aident à collecter les données de nos terminaux et nous facilite dans nos analyses forensiques. Ses fonctionnalités permettent aussi bien la recherche et l’extraction de preuve que l’analyse des données collectées : “Il a été entièrement conçu afin de fonctionner dans l’écosystème Microsoft Windows de façon décentralisée et à grande échelle” dit l’ANSSI. 5.5.3.2 L’analyse de données de compromission Hayabusa est un outil de réponse à incident développé par les professionnels de la sécurité de Yamato au Japon. Il permet d'analyser les événements Windows pour détecter les indices de compromission, d'examiner ces preuves et de créer une chronologie détaillée de l'attaque, entre autres fonctionnalités. Ensuite, une organisation de taille moyenne souhaitera sûrement automatiser de manière partielle certaines décisions faciles à prendre et sans impacts sur la gestion de l’incident comme le choix des terminaux à analyser dans la suite de l’investigation. 5.5.3.3 L’analyse de comportement anormal avec la prévention des intrusions En laissant la machine ou des outils identifier les éléments qui leur semblent suspects. Les composants et logiciels de type IPS (Intrusion Prevention System) bloquent activement les menaces en fonction des politiques de sécurité définies. Nous avons par exemple Palo Alto Networks Threat Prevention, un IPS qui détecte et bloque les exploits de vulnérabilité et les logiciels malveillants qu’il reconnaît. En acquérant de la maturité nous pourrons être amenés à automatiser les actions d’atténuation voire de remédiation sur les conséquences de l’attaque sur notre système d’information. 5.5.3.4 La réalisation automatique des actions d’atténuation Bloquer un utilisateur ou couper l’accès au réseau à un poste de travail sont des actions plutôt simples à exécuter quand nous sommes en pleine réponse à incident, se relayer sur un processus automatiser pour ces tâches connues d’avance, gâcherait du temps et des compétences que nous aurions pu investir dans de l’analyse de preuves. 5.5.3.5 L’automatisation de la réponse avec les plateformes SOAR Dans ce contexte l’intégration entre nos différents outils au sein de notre plateforme de sécurité accroît leur capacité d’apprentissage continue en mettant régulièrement à jour leur base de connaissance sur les alertes que nous avons déjà subies. Les solutions SOAR (Security Orchestration, Automation, and Response) aident concrètement les équipes de sécurité à gérer et à répondre aux incidents de sécurité de manière plus efficace et automatisée. Elles combinent l'orchestration, l'automatisation et la gestion des réponses aux incidents en un seul outil. Orchestration : Intégration des différents outils de sécurité et des processus pour assurer une réponse coordonnée et cohérente aux incidents. Automatisation : Exécution automatique de tâches répétitives et routinières pour réduire la charge de travail manuel et accélérer la réponse. Gestion des réponses : Centralisation des informations sur les incidents, la gestion des workflows, et la documentation des actions entreprises pour une meilleure analyse post-incident. Nous pouvons citer Splunk SOAR, une solution de sécurité présentant des fonctionnalités de SOAR qui s’intègre parfaitement avec CyberTriage une solution d’accompagnement à l’analyse forensique qui automatise un grand nombre d’actions répétitives pour un analyste, notamment La collecte d’artefacts L’identification de scénario d’attaque La priorisation d’éléments à analyser et la recommandation d’artefacts pour une investigation approfondie La réalisation de frises chronologiques de l’attaque La collaboration entre différents analystes directement au sein de l’outil Voici en somme les processus de sécurité que nous pouvons automatiser et optimiser, du cycle de développement à la réponse aux incidents. Ces standards de l’industrie nous aident à atteindre une posture idéale en matière de sécurité informatique. Toutefois l’implémentation de ces dernières doit être en adéquation avec nos besoins, notre contexte métier et notre maturité organisationnelle. En tant qu’ingénieur sécurité en apprentissage chez Shadow et ayant développé une appétence pour l’automatisation des processus de sécurité informatique en général et les pratiques DevSecOps en particulier, mon rôle a été de mettre en place les recommandations que nous venons d’étudier. Abordons donc les étapes concrètes et les outils que j’ai utilisés dans le contexte de mise en place d’une plateforme de sécurité automatisé chez Shadow. Mentionné dans la conférence : To Automate or Not to Automate : That is the Incident Response Question↩︎ L’article de RedHat Shift-Left vs Shift-Right aborde en profondeur ce sujet.↩︎ OWASP DevSecOps Guideline↩︎ What is DevSecOps↩︎ Shifting Security to the Left↩︎ OWASP DevSecOps Guideline↩︎ "],["mise-en-place-des-pratiques-au-sein-de-shadow.html", "Chapitre 6 Mise en place des pratiques au sein de Shadow 6.1 Shift Left Retro Planning 6.2 Pratiques DevSecOps chez Shadow 6.3 Automatisation des processus de détection et de réponse chez Shadow 6.4 Amélioration continue et prochaines étapes", " Chapitre 6 Mise en place des pratiques au sein de Shadow Dans son contexte et dans son processus de développement, Shadow prit la décision de s’orienter vers la philosophie DevOps en mettant en place un certain nombre de procédés et d’outillages pour automatiser la mise en condition opérationnelle de ses produits et de ses outils internes. Dans cette optique nous avons également voulu remettre la sécurité au centre de ces procédés pour nous permettre de réaliser un Shift Left avec nos processus de sécurité. Nous allons donc aborder dans cette partie les pratiques DevOps déjà en place chez Shadow avant de parler de notre plan vers le Shift Left puis nous verrons les actions et outils que j’ai mis en place pour concrétiser ce plan et nous finirons par une projection sur l’automatisation des processus de détection et de réponse. 6.1 Shift Left Retro Planning Pour commencer à Shift Left, la première des choses est de réaliser une prise de conscience au sein de l’équipe sécurité d’un besoin d’évolution en ce qui concerne les pratiques de sécurité déjà en place au sein du cycle de développement. Par la suite réaliser un Shift Left implique une symbiose entre évolution culturelle, entraînement, intégration d’outils et de nouveau processus. Pour cela, Florent, Head of Security chez Shadow, intégra dans la vision long terme de la politique de sécurité de Shadow des étapes en vue de réaliser un Shift Left au sein de nos processus. Parmi ces étapes nous pouvons retrouver : la sensibilisation des collaborateurs aux problématiques de sécurité de l’organisation, l’intégration de différents outils permettant l’automatisation de certains processus, la mise en places de pratiques DevSecOps, la gestion de vulnérabilité, la modélisation des menaces auxquelles Shadow pourrait faire face. Certaines de ces étapes ont pu être réalisées en parallèle pendant que d’autres nécessitent une certaine maturité organisationnelle pour être débutées comme la modélisation des menaces. Cela est possible car Shadow s’est naturellement tourné vers une approche DevOps dans sa genèse. Bien qu’elles ne soient pas un prérequis pour réaliser un Shift Left, les pratiques DevOps procurent une bonne base pour procéder à ce changement tout comme l’approche DevSecOps se présente comme un fil rouge pour nous aider dans notre démarche. 6.1.1 DevOps chez Shadow DevOps est avant tout une approche collaborative entre les équipes de développement et les équipes opérationnelles qui se suit par un certain nombre de pratiques et d’automatisation tout au long du cycle de développement. Shadow possède dans toutes ses équipes un cycle d’intégration continue et de déploiement continu (CI/CD). Ces derniers incluent la plupart du temps une phase de linting, packaging puis de build intégré à des outils relativement modernes bien que variant d’une équipe à l’autre. Par conséquent notre prochaine étape dans l’évolution de nos pratiques DevOps consiste à standardiser nos procédés et nos outils tout en incluant les tests de sécurité au plus tôt dans nos CI. 6.2 Pratiques DevSecOps chez Shadow Nous avons souligné que l'adoption d'une approche DevSecOps engage tous les métiers intervenant dans le cycle de développement, en les rendant responsables de la sécurité. Cette culture est tout aussi essentielle que l'automatisation des processus. C'est pourquoi nous avons mis en place un programme de sensibilisation à la sécurité informatique à destination de nos collaborateurs. 6.2.1 Programme de sensibilisation Pour établir une culture de collaboration sur les sujets de sécurité nous devons sensibiliser nos collaborateurs aux risques de sécurité, aux bonnes pratiques et aux différents types d’attaque qui existent, notamment celle à laquelle ils sont le plus susceptibles d’être vulnérable : le phishing. En effet la majorité des organisations qui se font compromettre réussissent un accès initial grâce aux phishings car un collaborateur n’a pas été assez précautionneux dans la vérification de l’authenticité de l'e-mail reçu. Mon objectif était donc de trouver une solution permettant de faire grandir les connaissances en sécurité de l’information au sein de sein de Shadow, tout en entraînant nos collègues à être alerte lors de la réception d’un e-mail paraissant suspect. Cela nous a nécessités différentes étapes Comprendre les lacunes et les besoins de renforcement en culture de sécurité informatique Entraîner nos collaborateurs de manière régulière Evaluer les progrès avec des exercices de simulations Répéter cela dans une optique d’amélioration continue Dans une philosophie d’automatisation de processus de sécurité, nous avons compris que réaliser ces étapes manuellement avec la taille de notre équipe de sécurité serait très chronophage et perdrait continuellement de la valeur par rapport à nos occupations quotidiennes. La charge qui m’a été accordée fut de faire une analyse comparative de différentes solutions et services de sensibilisation à la sécurité informatique proposant des modules d’entraînement. Je me suis donc basé sur la liste de fonctionnalité suivante avec leur priorité pour choisir une solution correspondant à nos besoins. (Voir annexe 2) Après avoir établi une liste de solutions open source et payantes, en priorisant les solutions européennes, car Shadow s'oriente vers la souveraineté numérique, j'ai dû évaluer chacune de ces solutions à travers des échanges commerciaux, des démonstrations et des phases de PoC (preuve de concept) sur une population donnée d'employés de Shadow, puis filtrer celles qui nous convenaient aussi bien fonctionnellement que financièrement. Le ressenti des futurs utilisateurs a également été pris en compte dans le choix de la solution, ce qui nous a permis d'obtenir une moyenne pondérée de chaque solution à l'aide des notes que les utilisateurs — nos collaborateurs — ont pu attribuer à ces solutions en se basant sur des critères préalablement définis. J’introduis donc Riot une solution dédiée à la sensibilisation à la sécurité informatique. Elle vise à former les employés d'une entreprise aux bonnes pratiques en matière de sécurité informatique. Riot propose une approche ludique et engageante pour aider les utilisateurs à mieux comprendre les menaces de sécurité et à adopter les comportements appropriés pour se protéger et protéger leur organisation. Voici quelques caractéristiques de Riot : Phishing Simulation : Riot permet de créer des campagnes de simulation d'attaques de phishing pour évaluer et former les employés à reconnaître les tentatives d'hameçonnage. Formation via Albert : La plateforme propose des modules interactifs et des quiz pour sensibiliser les utilisateurs aux risques liés à la sécurité informatique réaliser par Albert un robot qui envoie des messages de sensibilisation directement dans l'environnement de travail des utilisateurs, Slack pour notre cas. Personnalisation : Les contenus de formation peuvent être personnalisés en fonction de nos besoins et du niveau de connaissance des utilisateurs. Suivi et Reporting : Riot fournit des outils pour suivre l'engagement des utilisateurs et mesurer l'efficacité des campagnes de sensibilisation. Approche Ludique : Pour rendre l'apprentissage plus attractif, Riot intègre des éléments de gamification, comme des scores et des classements. Riot est pour nous un outil complet pour renforcer notre posture en sécurité informatique en impliquant activement nos collègues dans le processus de sensibilisation. Cela favorise une culture de collaboration et d'échange sur les sujets de sécurité que nous souhaitons instaurer. Parallèlement à cette sensibilisation continue, nous avons poursuivi notre programme de Shift Left en développant un outil de détection de valeurs secrètes pour nos projets internes versionnés sur GitLab 6.2.2 Détection de secrets La détection de secrets sur les projets versionnés est l’une des premières étapes dans un processus de Shift Left. L’objectif étant de s’assurer qu’aucune information sensible ne soit retrouvée sur un dépôt git. En effet plusieurs compromissions surviennent suite à la découverte d’informations sensibles poussée sur des projets comme des clés d’API. Nous devons donc analyser nos commits à la recherche de toutes données secrètes. L'approche idéale consiste à détecter et à prévenir l'exposition de données sensibles avant qu'elles n'atteignent le dépôt, car elles sont alors visibles dans l'historique. Dans le cas des plateformes d'hébergement de code, les secrets peuvent encore traîner sur le web et faire l'objet de recherches après avoir été retirés du dépôt. Une approche complémentaire consiste à analyser le dépôt à la recherche d'informations sensibles, puis à les supprimer ; il convient de noter que si des informations confidentielles sont divulguées, c'est qu'elles sont déjà compromises et qu'elles doivent être invalidées. La détection de secrets implique donc d’avoir une bonne méthodologie de gestion de secrets au sein de l’organisation. Nous utilisons la solution Vault de Hashicorp à cet effet. Elle permet de stocker les secrets de manière sécurisée, en les chiffrant avant de les sauvegarder dans une base de données. Vault fournit un système de contrôle d'accès rigoureux qui définit qui peut accéder à quels secrets. Les politiques d'accès peuvent être configurées pour permettre un contrôle granulaire. En plus de cela il est également possible de gérer la rotation des clés et de créer des automatisations avec toutes ces fonctionnalités. Chez Shadow notre plateforme de gestion de secrets est automatiquement déployée et configuré de manière déclarative en Infra as Code, réduisant d’office la charge de travail pour toutes les équipes. De ce fait nous savons que faire lors de l’identification d’un nouveau secret. 6.2.2.1 Comment détecter des secrets Pendant notre processus de réflexion sur la mise en place de cette pratique au sein des équipes de développement de Shadow, nous avons fait une étude sur la détection de secrets sur les dépôts git et l’endroit idéal pour le faire selon notre contexte. Il est intéressant de noter que Shadow, de son passé de start-up a gardé un long moment une philosophie delivery-first, c’est-à-dire prioriser la livraison aux détails opérationnels ou de sécurité. De ce fait chaque équipe n’est pas alignée sur un standard dans leur cycle de développement. Ainsi, dans une vision d’implémentation de bonnes pratiques et d’amélioration des processus en cours nous avons quelques contraintes organisationnelles et une once de nostalgie vis-à-vis des processus déjà en place. Nous avons vu que la détection de secrets peut se faire Localement avant que le code ne soit versionné à l’aide de pre-commit, ce qui implique une détection préalable du secret bien que dépendant de la volonté de l’utilisateur à implémenter l’outil proposé Pendant l’intégration continue (CI), un secret détecté à ce niveau serait déjà compromis, néanmoins l’équipe en charge serait la mieux placée pour juger de la pertinence du secret détecté, du processus d’invalidation et de la correction du code impliqué. Durant une analyse des sources après que le code ait été poussé, cela est à la charge de l’équipe sécurité et implique une bonne gestion des secrets remontée tout en prenant en compte l’identification des faux positifs. Le défaut étant que ce procédant est non bloquant dans le cycle de développement et le processus d’invalidation, restant à la charge des équipes de développement ne serait pas nécessairement immédiat. Cette dernière solution nous a paru être un bon compromis pour notre situation. Nous avons donc développé Gitleaker, une API de détection de secrets exposées qui agit à chaque fois qu’un nouveau code est poussé sur notre espace au sein de la plateforme GitLab et notifie l’auteur sur Slack en cas de nouveaux secrets exposés. 6.2.2.2 Gitleaker Gitleaker utilise gitleaks comme outil de détection de secrets, il permet de rechercher divers types d’information sensible en se basant sur le contenu de l’historique de commits. D’autres outils existent comme gittyleaks : Recherche d'informations sensibles pour un dépôt git un peu comme gitleaks, cependant il est plus vieux et moins maintenu que gitleaks. git-secrets : Empêche de versionner des secrets grâce à un module complémentaire qui s’intègre à la commande git. Voici un schéma d’architecture décrivant également le processus de traitement d’une requête Durant le processus de développement j’ai dû prendre en compte diverses contraintes pour assurer que l’API supporte de fortes charges et soit à même d’évoluer rapidement. D’où la présence d’un modèle de file d’attente utilisant Redis et la librairie python celery. J’ai également pu éprouver le cycle d’intégration et de déploiement en continu expliqué plus haut afin de justifier l’application de nouvelles pratiques DevSecOps nous permettant d’adopter une approche de Shift Left. La détection de secret n’est qu’une première brique dans l’exécution de tests de sécurité au sein de notre cycle d’intégration continue. La prochaine étape est d’ajouter des outils d’analyse statique et dynamique de code pour identifier les vulnérabilités qui s’y cache et d’avoir une approche de gestion de ces vulnérabilités permettant d’évaluer, atténuer ou remédier le risque d’exploitation de ces dernières. Dans cette optique nous avons identifié DefectDojo. 6.2.2.3 DefectDojo DefectDojo est une plateforme de gestion de vulnérabilités open source proposant des fonctionnalités d’importation de rapports d’une multitude d’outils de sécurité, de suivi d’état de la vulnérabilité — de l’identification à la remédiation ou l’acceptation — de déduplication avec les vulnérabilités déjà remontées et possède une API permettant de réaliser diverses intégrations et automatisation entre nos outils et les fonctionnalités offertes par la plateforme. En vue d’intégrer cette plateforme à notre catalogue, je me suis chargé de juger la pertinence de cette dernière dans un environnement local en créant un processus automatisé dont l’objet fut d’importer les résultats d’une analyse statique de code — utilisant Semgrep un outil d’analyse multilangage — réalisé à chaque nouveau code poussé sur le dépôt. L’objectif étant que chaque utilisateur ayant accès à la plateforme soit responsable de l’état de la vulnérabilité identifié, l’équipe sécurité s’occupant de l’accompagnement des équipes dans la qualification et les possibilités de remédiation. Concrètement ce processus automatisé se présente comme un ensemble de scripts bash intégré à GitLab CI, nous permettant de définir un grand nombre de flux et d’actions à réaliser suite à des événements survenant sur le dépôt. À moyen terme, nous avons l'intention de distribuer ce modèle pour l'intégrer à tous les projets de Shadow et faciliter ainsi l'intégration des outils d'analyse statique et dynamique à toutes les équipes. Pour poursuivre avec les processus de sécurité automatisés dans notre équipe, abordons comment les phases de détection et de réponse sont planifiées chez Shadow et quels procédés j’ai pu améliorer pour amoindrir la charge de travail de l’équipe sécurité. 6.3 Automatisation des processus de détection et de réponse chez Shadow 6.3.1 Détection En plus de la détection d’incident, chez Shadow nous avons également la détection de fraude et d’abus d’utilisation de nos services. En ce qui concerne Shadow PC, nous avons des requêtes au sein de nos différents outils qui remontent les paiements suspicieux et les comptes potentiellement abusifs, cependant le processus de vérification de ces alertes est chronophage et répétitif. Nous développons des plateformes et API internes pour réaliser certaines de ces tâches de manière automatiques. Pour Shadow Drive, j’ai eu l’honneur pendant mon projet de fin d’étude de mettre en place les premiers éléments de détections et de prévention d’intrusion sur notre infrastructure. En effet je mentionne dans mon mémoire que Nous avons donc vu qu’il était nécessaire de connaître avant toute chose les besoins de l’entreprise en termes de sécurité en réalisant une analyse de besoins suivie d’une analyse de risques. Puis de définir un protocole de test car il sera notre boussole lors de l’évaluation des solutions de sécurité qui s’offrent à nous. Dans notre cas, nous avons étudié les solutions éditées par OGO Security, CrowdSec et UBIKA qui sont des boîtes françaises spécialisés dans la cybersécurité. Cette étude nous a prouvé que l’agent CrowdSec était le meilleur compromis pour nous avec un rapport protection coût acceptable à l’heure actuelle. Enfin pour pérenniser la sécurité de notre infrastructure et l’efficacité de la solution choisie, nous avons jugé bon de définir un processus d’amélioration continue après avoir déployé en production ladite solution. (Olea, 2023) Depuis la mise ne place de manière industrielle de CrowdSec, nous avons commencé à être alertés des robots qui analysent internet à la recherche de vulnérabilités, à bloquer de manière automatique les comportements suspects et améliorer les capacités de la solution à ne pas notifier les faux positifs. De plus notre équipe étudie le déploiement de Wazuh un XDR présenté plus haut sur tous les terminaux et serveurs de l’entreprise pour une surveillance optimale des événements qui s’y produisent. En parallèle nous éprouvons également les possibilités de nos plateformes et outils à nous accompagner dans la résolution de nos incidents. Voyons donc comment nous y parvenons. 6.3.2 Réponse Comme vu dans l’Etat de l’art, automatiser la phase de réponse à incident en interne demande une certaine maturité de ses différents processus et un rapport bénéfice, coût, probabilité et impact d’une erreur sur le processus automatisé acceptable pour l’organisation. Chez Shadow notre gestion d’incident est grandement manuelle. Nous profitons des fonctionnalités de nos outils pour nos investigations et externalisons les cas d’analyse forensique. Par exemple, CrowdSec possède un mode replay qui permet de rejouer un fichier de journalisation afin d’y retrouver des signes de comportement malicieux et approfondir la recherche de preuves de compromission ou d’intrusion. Étant en cours de Shift Left, nous restons proactifs et définissons continuellement de nouvelles étapes dans notre démarche et apprenons à chaque nouveau jalon atteint dans notre planification. 6.4 Amélioration continue et prochaines étapes Dans une optique d’amélioration continue de nos processus, chez Shadow et en général, une équipe de sécurité se doit de remettre ses pratiques en question pour les faire évoluer. La sécurité est un voyage, il est tout à fait normal de changer de route lorsque celle que nous suivons semble nous éloigner de notre destination. C’est pourquoi, nous avons déjà prévu la suite de nos actions avec ce que nous avons déjà en place. L’ajout au sein de nos CI/CD d’outils d’analyse dynamique. Poursuivre avec la vérification en continue de conformité selon différents standards industriels comme SecNumCloud ou PCI DSS. Nous avons cité plus haut la gestion de vulnérabilité semi-automatisée avec la plateforme open source DefectDojo. La détection de comportements frauduleux dans le contexte de Shadow Drive grâce à CrowdSec notamment la création automatique de compte ou tout usage qui sortirait de nos conditions. L’implémentation de CrowdSec au sein de toutes les équipes afin de profiter de la fonctionnalité de partage d’information entre les différentes instances de la solution. L’affinement des processus de réponse et l’intégration de nos différents outils à une plateforme unique de gestion d’événements. Ces différents éléments sont une liste non exhaustive de ce que nous avons prévu de faire pour parfaire ce que nous faisons dans l’équipe sécurité tout en intégrant nos collaborateurs car nous avons un objectif commun : la satisfaction de nos utilisateurs en garantissant le maintien en condition opérationnelle de nos services. "],["conclusion.html", "Chapitre 7 Conclusion", " Chapitre 7 Conclusion En conclusion, à l'ère où l'agilité et la réactivité sont essentielles pour rester compétitif, il devient impératif d'intégrer la sécurité dès les premières phases du développement mais également faire évoluer ses processus de détection et de réponse en automatisant les tâches répétitives. Nous nous sommes demandé en début de cette thèse professionnelle comment la mise en place des pratiques de sécurité automatisée au sein des processus de développement peut améliorer la résistance des systèmes d'information aux menaces qui pèsent sur une organisation et augmenter la performance des équipes de sécurité car nous avons pris conscience de la charge de travail imputé aux équipes de sécurité dans un monde où presque toutes les équipes participant au développement d’un produit prennent des décisions de sécurité impactant toute l’organisation. D’où la nécessité de faire évoluer nos pratiques dans une vision collaborative de la sécurité de l’information. Au vu de ce qui précède, l’industrie recommande aujourd’hui d’opter pour une approche de Shift Left où nous intégrant la sécurité au plus tôt dans le cycle de développement. À cela nous ajoutons une part d’automatisation au sein des phases de détection de la menace et de réponse à incident pour redonner de la vélocité aux équipes perdant du temps dans des tâches sans grande valeur ajoutée à leur mission. Il est cependant intéressant de noter qu’un cycle de développement sécurisé ne comble pas un manquement de sécurité physique. De plus l’automatisation des processus peut grandement nous être utile tout en ajoutant des problèmes annexes comme le maintien des outils développés, la gestion des faux positifs impliquant d’améliorer les algorithmes développés ou d’appliquer des règles plus fines ou encore l’augmentation de la surface d’attaque de l’organisation en laisser passer de nouvelles vulnérabilités. Avec l’automatisation vient également un risque de perte de compétences, il devient difficile d’apprendre à de nouvelles recrues les tâches basiques si elles sont toutes automatisées. Enfin si tout le système mis en place vient à ne plus fonctionner et que les personnes en charge ne savent plus réaliser les tâches automatisées de manière manuelle, l’automatisation devient plus une épée de Damoclès qu’une solution au manque d’efficacité de l’équipe. En fin de compte l’automatisation des processus de sécurité et l’intégration de la sécurité au plus tôt dans le cycle de développement ne sont pas des solutions miracles mais sont des outils à utiliser de manière intelligente et sans dépendance pour que notre voyage nous semble léger. "],["bibliographie.html", "Chapitre 8 Bibliographie", " Chapitre 8 Bibliographie Bell, L., Brunton-Spall, M., Smith, R., &amp; Bird, J. (2017). Agile Application Security. O'Reilly Media, Inc. LaPiedra, J. (2002). The Information Security Process. SANS Institute. Lietz, S. (2015, 06 01). What is DevSecOps? Retrieved from devsecops.org: https://devsecops.org Lietz, S. (2016, 06 05). Shifting Security to the Left. Retrieved from devsecops.org: https://www.devsecops.org/blog/2016/5/20/-security Olea, G. (2023). Mise en place d'une stratégie de sécurité pour une plateforme SaaS d’outils collaboratifs. Reims. RedHat. (2024, 03 19). Shift left vs. shift right. Retrieved from RedHat: https://www.redhat.com/en/topics/devops/shift-left-vs-shift-right "],["annexes.html", "Chapitre 9 Annexes 9.1 Le cycle de développement sécurisé 9.2 Fonctionnalités d’une solution de sensibilisation à la sécurité", " Chapitre 9 Annexes 9.1 Le cycle de développement sécurisé 9.2 Fonctionnalités d’une solution de sensibilisation à la sécurité Fonctionnalité Priorité Simulateur de campagne de phishing 1 Personnaliser le contenu 1 Catalogue de cours et de documents de formation 1 Variété de modèles 1 Intégration Slack 1 Automatiser les simulations de phishing 2 Rapports d'analyse 2 Attribution de contenu dynamique 2 Suivi de l'apprentissage 2 Gamification de la sensibilisation 2 Interface Web 2 Facile à utiliser 2 Simulation de pièces jointes à des courriels 3 Évaluation du risque sur le point de défaillance de l'employé 3 Possibilité pour l'utilisateur de signaler un courriel 3 Interface graphique 4 IA / Holistique 4 []Tableau 1 Tableau de priorisation des fonctionnalités d'une solution de sensibilisation à la sécurité "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
